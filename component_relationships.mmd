```mermaid
graph LR
    subgraph "Component Dependencies"
        subgraph "Core Components"
            GC[GatedConvLSTM<br/>ğŸ§  Temporal Processing]
            LA[LocalAttention<br/>ğŸ‘ï¸ Spatial Attention]
            HB[HybridBlock<br/>ğŸ”— LSTM + Attention]
            
            GC --> HB
            LA --> HB
        end
        
        subgraph "Building Blocks"
            EB[EncodingBlock<br/>ğŸ“‰ Encoder]
            DB[DecodingBlock<br/>ğŸ“ˆ Decoder]
            
            HB --> EB
        end
        
        subgraph "Residual Components"
            RB[ResNetBlock<br/>ğŸ”„ Classic Residual]
            AB[AttentionBlock<br/>ğŸ”„ Residual Attention]
            CA[ChannelAttention<br/>ğŸ“Š Channel-wise]
            SA[SpatialAttention<br/>ğŸ—ºï¸ Spatial-wise]
            
            CA --> AB
            SA --> AB
        end
        
        subgraph "Main Network"
            FPN[FlowPredictionNet<br/>ğŸ¯ Main Network]
            
            EB --> FPN
            DB --> FPN
        end
    end
    
    subgraph "Residual Connection Types"
        subgraph "Type 1: Classic Residual"
            RB_Detail[ResNetBlock<br/>Input â†’ Conv â†’ BN â†’ ReLU â†’ Conv â†’ BN<br/>â†“<br/>Output = Input + Processed]
        end
        
        subgraph "Type 2: Skip Connections"
            Skip_Detail[DecodingBlock<br/>Encoder_Residual ----ğŸ”„---â†’ Decoder<br/>Output = Upsampled + Encoder_Residual]
        end
        
        subgraph "Type 3: Attention Residual"
            Attn_Detail[AttentionBlock<br/>Input â†’ Conv â†’ Channel_Attn â†’ Spatial_Attn<br/>â†“<br/>Output = Input + Processed]
        end
        
        subgraph "Type 4: Gating (Not Residual)"
            Gate_Detail[LocalAttention<br/>Input â†’ Conv â†’ Sigmoid<br/>â†“<br/>Output = Input * Attention_Weights]
        end
    end
    
    subgraph "Processing Flow"
        direction TB
        Input_Frames[Input: I0, I1]
        
        subgraph "Encoder Stages"
            E1[Encoder1<br/>HÃ—W â†’ H/2Ã—W/2]
            E2[Encoder2<br/>H/2Ã—W/2 â†’ H/4Ã—W/4]
            E3[Encoder3<br/>H/4Ã—W/4 â†’ H/8Ã—W/8]
        end
        
        subgraph "Decoder Stages"
            D1[Decoder1<br/>H/8Ã—W/8 â†’ H/4Ã—W/4]
            D2[Decoder2<br/>H/4Ã—W/4 â†’ H/2Ã—W/2]
            D3[Decoder3<br/>H/2Ã—W/2 â†’ HÃ—W]
        end
        
        Flow_Output[Optical Flow<br/>F_0_1, F_1_0]
        
        Input_Frames --> E1
        E1 --> E2
        E2 --> E3
        E3 --> D1
        D1 --> D2
        D2 --> D3
        D3 --> Flow_Output
        
        %% Skip connections
        E1 -.->|res1 ğŸ”„| D3
        E2 -.->|res2 ğŸ”„| D2
        E3 -.->|res3 ğŸ”„| D1
    end
    
    subgraph "LSTM State Management"
        direction TB
        T0[Time Step 0<br/>Initialize States]
        T1[Time Step 1<br/>Update States]
        State[Hidden & Cell States<br/>Temporal Memory]
        
        T0 --> State
        State --> T1
        T1 --> State
    end
    
    %% Styling
    classDef residual fill:#ffdddd,stroke:#ff0000,stroke-width:2px
    classDef lstm fill:#ddffdd,stroke:#00aa00,stroke-width:2px
    classDef attention fill:#ddddff,stroke:#0000ff,stroke-width:2px
    classDef main fill:#fff9dd,stroke:#ff9900,stroke-width:3px
    
    class RB,AB,Skip_Detail,RB_Detail,Attn_Detail residual
    class GC,HB,State,T0,T1 lstm
    class LA,CA,SA,Gate_Detail attention
    class FPN,Flow_Output main
```